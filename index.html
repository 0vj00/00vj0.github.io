Hello World!!

ILSVRC history:
Classification: Alexnet, Zeiler & Fergus, GoogLeNet (VGG), ResNet 
Localization: Alexnet, OverFeat, VGG, ResNet + RPN
Detection: ?, OverFeat, UvA-Euvision, GoogLeNet, ResNet + Faster-R-CNN

Datasets:
NORB
Caltech 101 / 256
CIFAR 10 / 100
MNIST
Imagenet - 15 million labeled images / 22000 categories
ILSVRC - 1.2 million labeled images, 50000 validation, 150000 testing. ~1000 images in each of 1000 categories
ILSVRC 2010 - test set labels are available

ILSVRC 2013 - localization considered correct only if > 50% overlap (intersection-over-union)
detection challenge may have zero objects (i.e. background class). background class makes detection harder.
localization and classification share data. detection has few more data points: images where the objects are smaller, images where
certain objects are absent (can be used for background class)

Preprocessing:


Regularization:
Data augmentation - adding noise, cropping, flipping, altering intensity of RGB images
Alexnet style RGB intensity alteration - collect all RGB values (3D vector) from all training images. PCA to compute eigenvectors 
and eigenvalues. Alter each training image by adding all three PCA directions scaled by their eigenvalue * N(0,0.1). Note: all 
pixels in image use the same gaussian sample but different images use different ones.
Dropout - reduces co-adaptation of features. increases the number of iterations needed to converge. e.g. w/ 0.5, alexnet needs
roughly 2X iterations (note: alexnet runs dropout only on two FC layers but these layers have most of the parameters)

Misc:
LRN - local response normalization - post Relu; normalize the activation by L2 norm of activations from 
neighboring kernels (n/2 on either side) raised to beta (hyperparameter). 
This ties the activations together, e.g. two activations can't both be high
Image similarity can be determined by L2 norm on the last hidden layer's representation of image. E.g. when used on ILSVRC, this 
retrieves similar images which in pixel-level-L2 would be far off.

Optimization:
GD:
SGD:
Momentum:
Nesterov Momentum:
AdaGrad:
RMSProp:
Adam:


conv layer: for 1 based indexing: op dimension = floor( 1 + (ip dimension - kernel dimension + padding) / stride )

Title: ImageNet Classification with Deep Convolutional Neural Networks

Notes: 
60 million params, 650K neurons, dropout regularization, Relu
ILSVRC 2010 & 2012
1.2 million labeled images
5-6 days on 2 GTX580
rescaled img such that shorter side of image is 256. central 256x256 cropped out
subtracted the mean value, over training set, per pixel
LRN - local response normalization - reduces error rates by ~1.2%
Overlapping Pooling - makes it slightly harder to overfit

Architecture:
Relu activations throughout
ip layer: 224 X 224 X 3
kernels:  11 X 11 ; stride 4
layer 2:  55 X 55 X 96
LRN: neighborhood 5, beta 0.75, alpha, k
max pool: 3 x 3; stride 2
kernels:  5 X 5 ; stride 
layer 3:  27 X 27 X 256
LRN: same as above
max pool: 3 X 3; stride 2
kernels: 3 X 3 ; stride
layer 4: 13 X 13 X 384
kernels: 3 X 3 ; stride 
layer 5: 13 X 13 X 384
kernels: 3 X 3 ; stride
layer 6: 13 X 13 X 256
max pool: 3 X 3; stride 2
dropout: 0.5
layer 7: FC 4096
dropout: 0.5
layer 8: FC 4096
op layer: softmax 1000
Data augmentation - 2048 X increase in training set by cropping random 224x224 regions + their horizontal flips.
10 X during testing by considering the four corners, center + their horizontal flips
Learning: SGD, 0.9 momentum, mini-batch 128, 0.0005 weight decay. learning rate set to 0.01 and reduced 10X manually based on 
validation error. during training it went through 3 reductions. 
weight decay is not just regularizing. it helps reduce training error as well.
Initialization: weights are N(0,0.01). biases in layers 3, 5, 6 are set to 1; remaining are set to 0.
Training consumed 90 cycles of the entire training set (1.2 million images)

Results:
ILSVRC 2010: top 1: 37.5%; top 5: 17.0%; top 5 w/o avg-ing over 10 patches: 18.3%
ILSVRC 2012: top 5: 18.2%; 5 CNN avg top 5: 16.4%
Removing any of the conv layers results in 2% loss on top 1 performance.

OverFeat:
single convnet for classification, localization and detection.
avoid training on background class.
ILSVRC 2012 and 2013. Winner of 2013 localization.

Training:
Trained on ILSVRC 2012 (1.2 million images)
Image is rescaled so the smaller dimension is of 256 pixels. 
Extract 5 random crops (221 X 221) and feed them + their horizontal flips in mini-batches of 128.
weights initialized to N(0,0.01)
SGD with momentum 0.6, weight decay 0.00001
Learning rate: 0.05 and reduced 2X at (30, 50, 60, 70, 80) epochs

Architecture:
Training treats architecture as non-spatial (i.e. 1x1 output) but inference treats it as spatial.
Relu activations throughout
(typo in their paper on the first two layers of the fast model?)
Fast model:
ip layer: 221 X 221 X 3
kernels: 11 X 11; stride 4
max pool: 2 X 2; stride 2
layer 1: 28 X 28 X 96
kernels: 5 X 5; stride 1
max pool: 2 X 2; stride 2
layer 2: 12 X 12 X 256
padding: 1 all around
kernels: 3 X 3; stride 1
layer 3: 12 X 12 X 512
padding: 1 all around
kernels: 3 X 3; stride 1
layer 4: 12 X 12 X 1024
padding: 1 all around
kernels: 3 X 3; stride 1
max pool: 2 X 2; stride 2
layer 5: 6 X 6 X 1024
FC:
layer 6: 1 X 1 X 3072
FC:
layer 7: 1 X 1 X 4096
softmax: 1000 classes

